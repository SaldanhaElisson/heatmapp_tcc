Projeto Eye-Tracking com JsPsych (WebGazer)
Este projeto implementa um experimento de eye-tracking (rastreamento ocular) baseado na web, utilizando a biblioteca JsPsych e a extens√£o WebGazer.js para capturar dados de olhar via webcam. A aplica√ß√£o √© constru√≠da com Vite, React e TypeScript, e os dados coletados podem ser analisados offline com scripts Python para gerar heatmaps.
üöÄ Funcionalidades
Rastreamento Ocular Baseado em Webcam: Utiliza o WebGazer.js para estimar a localiza√ß√£o do olhar do participante na tela.
Calibra√ß√£o e Valida√ß√£o Interativa: Inclui etapas de calibra√ß√£o por clique e valida√ß√£o de precis√£o para garantir a qualidade dos dados, com feedback visual ao participante.
Recalibra√ß√£o Condicional: Oferece tentativas de recalibra√ß√£o autom√°tica se a precis√£o inicial n√£o for satisfat√≥ria.
Upload Din√¢mico de Est√≠mulos: Permite que o usu√°rio fa√ßa o upload de imagens no navegador para serem usadas como est√≠mulos no experimento.
Exporta√ß√£o de Dados: Os dados brutos do experimento s√£o automaticamente salvos em um arquivo CSV local.
Gera√ß√£o de Heatmaps (Python): Script Python para processar os dados CSV e gerar heatmaps, visualizando a densidade do olhar sobre as imagens de est√≠mulo.
Desenvolvimento Moderno: Constru√≠do com Vite, React e TypeScript para uma experi√™ncia de desenvolvimento r√°pida e segura.
üõ†Ô∏è Tecnologias Utilizadas
Frontend:
Vite: Ferramenta de build r√°pida e eficiente.
React: Biblioteca JavaScript para constru√ß√£o de interfaces de usu√°rio.
TypeScript: Superset do JavaScript que adiciona tipagem est√°tica.
JsPsych: Framework para cria√ß√£o de experimentos de psicologia e neuroci√™ncia baseados na web.
WebGazer.js: Biblioteca de eye-tracking via webcam (vers√£o fork do JsPsych).
An√°lise de Dados (Offline):
Python: Linguagem de programa√ß√£o.
NumPy: Biblioteca para computa√ß√£o num√©rica.
Pandas: Biblioteca para an√°lise e manipula√ß√£o de dados.
Matplotlib: Biblioteca para cria√ß√£o de gr√°ficos (usada para heatmaps).
PIL (Pillow): Biblioteca para processamento de imagens.
‚öôÔ∏è Como Configurar e Rodar
Siga os passos abaixo para configurar e executar o projeto em seu ambiente local.
1. Pr√©-requisitos
Node.js e npm (ou Yarn): Certifique-se de ter o Node.js (vers√£o 20 ou superior recomendada) e o npm (ou Yarn) instalados.
Python: Certifique-se de ter o Python (vers√£o 3.8 ou superior recomendada) instalado.
Git: Para clonar o reposit√≥rio.
2. Configura√ß√£o do Projeto
Clone o reposit√≥rio:
git clone [URL_DO_SEU_REPOSITORIO]
cd [pasta_do_seu_projeto]

(Substitua [URL_DO_SEU_REPOSITORIO] e [pasta_do_seu_projeto] pelos valores corretos).
Instale as depend√™ncias do Frontend:
npm install
# ou
yarn install


Instale as depend√™ncias do Python:
√â recomend√°vel criar um ambiente virtual Python para suas depend√™ncias.
python -m venv venv
# No Windows:
# .\venv\Scripts\activate
# No macOS/Linux:
source venv/bin/activate

pip install numpy pandas matplotlib Pillow scipy


3. Rodando o Experimento (Frontend)
Inicie o servidor de desenvolvimento:
npm run dev
# ou
yarn dev


A aplica√ß√£o ser√° aberta no seu navegador (geralmente em http://localhost:5173).
Permita o acesso √† webcam quando solicitado.
Fa√ßa o upload das suas imagens e siga as instru√ß√µes para calibra√ß√£o e para rodar o experimento.
Ao final do experimento, um arquivo .csv contendo os dados do eye-tracking ser√° salvo automaticamente em sua pasta de downloads.
4. Gerando Heatmaps (Python)
Ap√≥s coletar os dados CSV, voc√™ pode usar o script Python para gerar heatmaps.
Organize suas pastas de dados:
Crie uma pasta chamada dados_eye_tracking na raiz do seu projeto.
Mova todos os arquivos .csv gerados pelo experimento para dentro dessa pasta (ex: eye-tracking-data.csv, eye-tracking-data (2).csv).
Crie uma pasta chamada imagens_originais na raiz do seu projeto.
Coloque todas as imagens originais que foram utilizadas como est√≠mulos no experimento dentro dessa pasta. O script precisa dessas imagens para desenhar os heatmaps sobre elas.
Execute o script de heatmap:
No terminal (com o ambiente virtual Python ativado), na raiz do seu projeto, execute:
python main.py


Resultados:
Uma nova pasta chamada matriz_gazes ser√° criada na raiz do seu projeto.
Dentro dela, para cada arquivo CSV processado, uma subpasta (com o nome do CSV) ser√° criada.
Os heatmaps gerados (arquivos .png) e as matrizes de gaze (.npy) ser√£o salvos nessas subpastas.
5. Docker (Opcional: Para Ambiente de Produ√ß√£o)
Voc√™ pode construir e rodar a aplica√ß√£o frontend em um cont√™iner Docker para um ambiente de produ√ß√£o ou para garantir consist√™ncia de ambiente.
Construa a imagem Docker:
No diret√≥rio raiz do projeto (onde est√° o Dockerfile), execute:
docker build -t eye-tracking-app .


Execute o cont√™iner Docker:
docker run -p 80:5173 eye-tracking-app

Isso mapeia a porta 80 do seu host (m√°quina local) para a porta 5173 do cont√™iner. Voc√™ pode acessar a aplica√ß√£o em http://localhost.
üí° Dicas para Melhorar a Precis√£o do Eye-Tracking
Para obter os melhores resultados com o WebGazer.js:
Ilumina√ß√£o: Realize o experimento em um ambiente bem iluminado, mas evite luz forte diretamente atr√°s do participante (contra-luz), que pode criar sombras ou reflexos.
Posicionamento da Cabe√ßa: O participante deve manter a cabe√ßa o mais parada poss√≠vel durante a calibra√ß√£o e a coleta de dados.
Dist√¢ncia da C√¢mera: Mantenha uma dist√¢ncia consistente da webcam.
Feche Outros Programas: Pe√ßa aos participantes para fechar outros aplicativos e abas do navegador n√£o essenciais para liberar recursos do sistema.
Feedback Visual: As bolinhas de previs√£o de olhar durante a calibra√ß√£o s√£o essenciais. Incentive o participante a tentar fazer com que a bolinha siga seu olhar com precis√£o.
ü§ù Contribui√ß√£o
Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues ou pull requests.
